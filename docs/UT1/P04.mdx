---
title: "Práctica 04"
description: Selecting and Validating models
tags: ["Cross Validation", "K-Fold", "Random Forest", "Data Leakage"]
---

Esta práctica consiste en la prevención de data leakage utilizando un cross-validation pipeline para luego comparar
los modelos utilizando las métricas obtenidas.

- **Propuesta:** https://juanfkurucz.com/ucu-ia/ut1/05-validacion-seleccion-modelos/
- **Link colab:** https://colab.research.google.com/drive/1cFAjRmqcqu3bhxJ3nNQphKIY2vYG0RR-?usp=sharing

## Objetivos
- Aprender a prevenir data leakage usando pipelines
- Implementar validación cruzada (cross-validation) robusta
- Comparar múltiples modelos de forma sistemática
- Interpretar métricas de estabilidad y selección de modelos

## Análisis y resultados
Los modelos evaluados son Logistic Regression, Ridge Classifier y Random Forest, utilizando la métrica Accuracy con
StratifiedKFold (5 folds) para la validación.

- **Logistic Regression:** 0.7618 ± 0.0061
- **Ridge Classifier:** 0.7509 ± 0.0032
- **Random Forest:** 0.7658 ± 0.0064

<img src="/ia-portfolio/p05_1.png" alt="..." />

<img src={`${process.env.NEXT_PUBLIC_BASE_PATH || ''}/p05_1.png`} alt="distribuciones" />

![Scores](/p04_1.png)
![Accuracy](/p04_2.png)

<br></br>
En los resultados Random Forest obtiene el mayor accuracy promedio (0.7658), superando por un margen pequeño a Logistic
Regression (0.7618). <br></br>

Todos los modelos presentan desviaciones estándar bajas (&lt;0.01), lo que indica alta consistencia entre los folds.
<br></br>

Ridge Classifier es el más estable (±0.0032), aunque con menor accuracy.

### Observaciones
- Random Forest es el ganador en rendimiento a nivel general.
- Ridge Classifier es el más consistente pero menos preciso.
- Logistic Regression se mantiene competitivo en ambas dimensiones.

Random Forest es el mejor modelo para este dataset, al ofrecer el mayor accuracy sin sacrificar estabilidad. Sin
embargo, si la prioridad fuese minimizar variabilidad, el Ridge Classifier podría ser considerado.

### Preguntas
#### **¿Qué es data leakage y por qué es peligroso?**
Es cuando el modelo tiene acceso, directa o indirectamente, a información del conjunto de prueba o a variables que no
debería conocer durante el entrenamiento. En la práctica, el modelo falla en datos reales porque nunca tuvo que
generalizar bien.

Causa resultados demasiado optimistas en validación.

#### **¿Cuándo usar KFold vs StratifiedKFold?**
**KFold** divide los datos en *k*-partes sin preocuparse de la proporción de clases. Esto es útil cuando las clases
están bien balanceadas.<br></br>

**StratifiedKFold** mantiene la misma proporción de clases en cada fold y se usa cuando hay clases desbalanceadas
(por ejemplo, 5% de pacientes enfermos y 95% sanos). Además evita que un fold quede sin ejemplos de la clase minoritaria.

#### **¿Cómo interpretar "95.2% ± 2.1%" en cross-validation?**
El modelo, en promedio, acierta el 95.2% de las veces y el rendimiento varía entre folds por un 2.1%. Un valor pequeño
indica consistencia/estabilidad.

#### **¿Por qué Random Forest no necesita StandardScaler?**
Porque Random Forest no usa distancia ni magnitudes absolutas de las variables, solo compara umbrales de
división (ej: "¿X &gt; 3.5?"), entonces no importa si una variable está en cm, mm o metros, al final el escalado no afecta
al resultado.

#### **En diagnóstico médico, ¿prefieres un modelo con 98% accuracy pero inestable, o 95% accuracy pero muy estable?**
Prefiero el 95% estable, porque en diagnóstico médico la confiabilidad es más importante que el rendimiento máximo
aislado.