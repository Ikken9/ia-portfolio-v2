import Image from 'next/image'

---
title: "Práctica 05"
description: Clustering y PCA - Mall Customer Segmentation
tags: ["Clustering", "PCA", "OneHotEncoder", "Data Normalization"]
---

Esta práctica consiste en aplicar técnicas de aprendizaje no supervisado, específicamente Clustering (K-Means) y
Análisis de Componentes Principales (PCA), con el objetivo de explorar y extraer información de un dataset sin etiquetas.

- **Propuesta:** https://juanfkurucz.com/ucu-ia/ut1/06-clustering-pca/#fase-2-data-understanding
- **Link colab:** https://colab.research.google.com/drive/1OpB48jQtHuJmvB70skZ777HRUwHQ6LQt?usp=sharing

## Objetivos
- Aprender a utilizar PCA para reducir la dimensionalidad de los datos.
- Aplicar algoritmos de clustering para identificar grupos o patrones subyacentes en los datos.

## Análisis
El dataset utilizado es el [Mall Customer Segmentation Dataset](https://www.kaggle.com/datasets/vjchoudhary7/customer-segmentation-tutorial-in-python/data) que contiene información
demográfica y comportamental real de clientes de centros comerciales.

<br></br>
**Primeras 5 filas del dataset:**

| Index | Customer ID | Genre | Age | Annual Income (k$) | Spending Score (1-100) |
|:------|:-----------:|:-----:|:---:|:------------------:|:----------------------:|
| 0     | 1           | Male  | 19  | 15                 | 39                     |
| 1     | 2           | Male  | 21  | 15                 | 81                     |
| 2     | 3           | Female| 20  | 16                 | 6                      |
| 3     | 4           | Female| 23  | 16                 | 77                     |
| 4     | 5           | Female| 31  | 17                 | 40                     |

<br></br>
**Estadísticas descriptivas:**

| Statistic | Customer ID | Age  | Annual Income (k$) | Spending Score (1-100) |
| :-------- | :---------: | :--: | :----------------: | :--------------------: |
| count     | 200.0       | 200.0| 200.0              | 200.0                  |
| mean      | 100.5       | 38.85| 60.56              | 50.2                   |
| std       | 57.88       | 13.97| 26.26              | 25.82                  |
| min       | 1.0         | 18.0 | 15.0               | 1.0                    |
| 25%       | 50.75       | 28.75| 41.5               | 34.75                  |
| 50%       | 100.5       | 36.0 | 61.5               | 50.0                   |
| 75%       | 150.25      | 49.0 | 78.0               | 73.0                   |
| max       | 200.0       | 70.0 | 137.0              | 99.0                   |

<br></br>
En el dataset los géneros están distribuidos de la siguiente forma:
- **Female:** 56.0%
- **Male:** 44.0%

<br></br>
Y los rangos observados son:
- **Age:** 18 - 70 (promedio: 38.9)
- **Annual Income (k$):** 15 - 137 (promedio: 60.6)
- **Spending Score (1-100):** 1 - 99 (promedio: 50.2)

<br></br>

### Distribuciones de Variables Clave
<Image src={`${process.env.PAGES_BASE_PATH || ''}/p05_1.png`} alt="distribuciones" />

<br></br>

### Relaciones Entre Variables
![relaciones](/p05_2.png)

<br></br>

### Matriz de Correlación - Mall Customers
![matriz](/p05_3.png)

Aquí puede observarse que la relación más fuerte es entre **Annual Income (k$)** y **Spending Score (1-100)**, con un
score de 0.010

<br></br>

####
### Análisis Comparativo por Género

|   Género   | Estadística | Edad  | Ingreso Anual (k$) | Puntuación de Gasto (1-100) |
| :--------- | :---------- | :---- | :----------------: | :-------------------------: |
| **Mujer**  |    Media    | 38.10 |       59.25        |             51.53           |
|            |     Std     | 12.64 |       26.01        |             24.11           |
| **Hombre** |    Media    | 39.81 |       62.23        |             48.51           |
|            |     Std     | 15.51 |       26.64        |             27.90           |

### Clustering
Se decide usar las características **Age**, **Annual Income (k$)** y **Spending Score (1-100)** porque son numéricas e
informativas.
<br></br>
Luego de una codificación de las variables categóricas, se crea el siguiente dataset:<br></br>

**Shape:** `(200, 5)`<br></br>
**Columnas:** `['Age', 'Annual Income (k$)', 'Spending Score (1-100)', 'Genre_Female', 'Genre_Male']`<br></br>
**Variables numéricas:** `['Age', 'Annual Income (k$)', 'Spending Score (1-100)']`<br></br>
**Variables categóricas codificadas:** `['Genre_Female', 'Genre_Male']`<br></br>

Ahora es necesaria la normalización de los datos, puesto que las variables utilizan escalas diferentes. Con el objetivo
de determinar el scaler más adecuado, tres son utilizados y comparados:

- **MinMaxScaler**
- **StandardScaler**
- **RobustScaler**

![scalers](/p05_4.png)

<br></br>

Como los datos ahora están normalizados, es esperable un cambio en la forma de la distribución de las variables, el
siguiente gráfico muestra una comparación de las diferentes distribuciones según el scaler utilizado, sobre la variable
**Annual Income**:

![scalers_annual_income](/p05_5.png)

<br></br>

Para determinar el mejor scaler, la métrica Silhouette Score es utilizada:

- **MinMax:** Silhouette Score = 0.364
- **Standard:** Silhouette Score = 0.332
- **Robust:** Silhouette Score = 0.298

<br></br>

Resultando MinMax como el que funciona mejor (mayor score).

### PCA
El objetivo es reducir la dimensionalidad de los datos a solo 2 dimensiones usando PCA. Esto permite visualizar los
datos en un gráfico 2D y entender qué variables originales contribuyen más a la estructura de los datos.
<br></br>
Entonces se ejecuta un PCA para analizar cuánta información (varianza) contiene cada componente y decidir
cuántas componentes son necesarias para retener la mayor parte de la información.
<br></br>
Luego se genera una lista que contiene el porcentaje de varianza que explica cada componente
principal (PC1, PC2, PC3...). La primera componente (PC1) siempre explica la mayor varianza, la segunda (PC2) la
siguiente mayor, y así sucesivamente.
<br></br>
Algo bueno es encontrar el número mínimo de componentes necesarias para alcanzar al menos el 90% (o 95%) de varianza
explicada, pero para visualización se eligen 2 componentes porque no es posible graficar en 3 dimensiones o más.
<br></br>

#### Varianza
![varianza](/p05_6.png)

<br></br>

#### Mall Customers en Espacio PCA 2D
![varianza_componentes](/p05_7.png)

<br></br>

## Feature Selection vs. PCA
Aquí el objetivo es determinar qué método es mejor para preparar los datos para clustering:
- Seleccionar las características originales más importantes (Feature Selection).
- Transformar todas las características en nuevas combinaciones (PCA).

<br></br>

Para la parte de Feature Selection se utilizan dos técnicas conocidas:
- **Forward Selection:** Comienza con cero características y añade una por una la que más mejora el modelo.
- **Backward Selection:** Comienza con todas las características y elimina una por una la menos importante.

<br></br>

En total se comparan 4; Baseline, Forward Selection, Backward Selection y PCA (2D).

<br></br>

**Resultados:**
- Baseline (todas): 0.364
- Forward Selection: 0.573
- Backward Elimination: 0.573
- PCA (2D): 0.686

#### Comparación de Métodos de Feature Selection
![comparación](/p05_8.png)

El PCA (2D) es el que tiene más score, por lo tanto es el más adecuado para usar.

Ahora es necesario descubrir grupos naturales de clientes (segmentos) dentro de los datos preparados de manera que los
clientes dentro de cada grupo sean muy similares entre sí y muy diferentes a los de otros grupos. Aquí es donde entra en
juego el algorítmo **K-Means**, que requiere saber un número de clusters (K).
<br></br>
Para encontrar el **K** óptimo se utiliza el Elbow Method junto con Silhouette Analysis.

<br></br>

#### Elbow Method - Silhouette Analysis
![elbow_silhouette](/p05_9.png)

<br></br>

**Candidato por Elbow Method:** K=6
**Candidato por Silhouette:** K=2 (score=0.762)

Elbow sugiere K=6, Silhouette sugiere K=2, considerando el contexto de negocio (3-5 segmentos esperados) se elege un
K = 4.

Tras elegir K, se entrena el modelo final de K-Means, se asignan las etiquetas de cluster a cada cliente.

<br></br>

### Análisis de Segmentación
<br></br>

---

**CLUSTER 0** (57 clientes, 28.5%)<br></br>
**Perfil Demográfico:**
- Edad promedio: 28.4 años
- Distribución género: 'Female': 57
<br></br>
**Perfil Financiero:**
- Ingreso anual: $59.7k
- Spending Score: 67.7/100

---

**CLUSTER 1** (47 clientes, 23.5%)<br></br>
**Perfil Demográfico:**
- Edad promedio: 50.1 años
- Distribución género: 'Male': 47
<br></br>
**Perfil Financiero:**
- Ingreso anual: $62.2k
- Spending Score: 29.6/100

---

**CLUSTER 2** (55 clientes, 27.5%)<br></br>
**Perfil Demográfico:**
- Edad promedio: 48.1 años
- Distribución género: 'Female': 55
<br></br>
**Perfil Financiero:**
- Ingreso anual: $58.8k
- Spending Score: 34.8/100

---

**CLUSTER 3** (41 clientes, 20.5%)<br></br>
**Perfil Demográfico:**
- Edad promedio: 28.0 años
- Distribución género: 'Male': 41
<br></br>
**Perfil Financiero:**
- Ingreso anual: $62.3k
- Spending Score: 70.2/100

### Clustering
![clustering](/p05_10.png)

